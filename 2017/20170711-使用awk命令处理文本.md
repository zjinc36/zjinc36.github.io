#   使用awk命令处理文本
+ date: 2017-07-11 15:10:40
+ description: 使用awk命令处理文本
+ categories:
  - Ubuntu
+ tags:
  - Linux命令
---
#   案例
1.  使用awk批量修改文件名
```shell
#   命令
#   将01_abc_def文件名变更为0100_abc_def文件名
ll | awk '{print $9}' | awk -F '_' '{if ($1 * 100 < 3901 && $1 * 100 > 1){if ($3){printf("mv %s \t %s \n", $0, $1 "00_"$2 "_"$3)} else {printf("mv %s \t %s \n", $0, $1 "00_"$2)}}}' | sh

#   稍微分解一下
#   查看所有文件
ll

# 获取文件名列
awk '{print $9}'

# 处理文本,得到"mv 01_abc_def 0100_abc_def"语句
awk -F '_' '{if ($1 * 100 < 3901 && $1 * 100 > 1){if ($3){printf("mv %s \t %s \n", $0, $1 "00_"$2 "_"$3)} else {printf("mv %s \t %s \n", $0, $1 "00_"$2)}}}'
# ====> 相当与 <====
awk -F '_' # 分割字符串,分割符为'_'
{
    if ($1 * 100 < 3901 && $1 * 100 > 1) {  # 排除一些不需要修改的
        if ($3) {   # 当第三列存在时
            printf("mv %s \t %s \n", $0, $1 "00_"$2 "_"$3)  # 拼接字符串用双引号将要拼接的字符串引起来
        } else {    # 当第三列不存在时
            printf("mv %s \t %s \n", $0, $1 "00_"$2)
        }
    }
}

sh  # 执行前面的文本
```

2.  使用 awk 过滤 history 输出，找到最常用的命令
```shell
history | awk '{a[$2]++}END{for(i in a){print a[i] " " i}}' | sort -rn | head
```

3.  过滤文件中重复行
```shell
awk '!x[$0]++' <file>
```

4.  将一行长度超过 72 字符的行打印
```shell
awk 'length>72' file
```

5.  查看最近哪些用户使用系统
```shell
last | grep -v "^$" | awk '{ print $1 }' | sort -nr | uniq -c
```

6.  假设有一个文本，每一行都是一个 int 数值，想要计算这个文件每一行的和，可以使用
```shell
awk '{s+=$1} ENG {printf "%.0f", s}' /path/to/file
```

#   调用awk
```
1.命令行方式
awk [-F  field-separator]  'commands'  input-file(s)
其中，commands 是真正awk命令，[-F域分隔符]是可选的。 input-file(s) 是待处理的文件。
在awk中，文件的每一行中，由域分隔符分开的每一项称为一个域。通常，在不指名-F域分隔符的情况下，默认的域分隔符是空格。

2.shell脚本方式
将所有的awk命令插入一个文件，并使awk程序可执行，然后awk命令解释器作为脚本的首行，一遍通过键入脚本名称来调用。
相当于shell脚本首行的：#!/bin/sh
可以换成：#!/bin/awk

3.将所有的awk命令插入一个单独文件，然后调用：
awk -f awk-script-file input-file(s)
其中，-f选项加载awk-script-file中的awk脚本，input-file(s)跟上面的是一样的。
```

#   使用说明
##  基本格式
```shell
awk [options] 'script' file
```

##  awk 同时处理多个文件
```shell
awk '{print FILENAME "\t" $0}' demo1.txt demo2.txt
```

##  awk 自定义分隔符
```shell
awk -F ':' '{print $1}' /etc/passwd

# nectarine(200g)2008 -> nectarine 200g 2008
awk -F '[()]' '{print $1, $2, $3}' some.log
```
+   awk 默认的分割符为空格和制表符
+   分割后的字段依次用 $1, $2,$3 来表示
+   $0 表示字符串本身
+   在 -F 参数中使用一对方括号来指定多个分隔符，awk 处理 some.log 文件时就会使用 “(“ 或者 “)” 来对文件的每一行进行分割

##  在 awk 中使用正则表达式
```shell
#   待匹配文本
This above all: to thine self be true
There is nothing either good or bad, but thinking makes it so
There’s a special providence in the fall of a sparrow
No matter how dark long, may eventually in the day arrival

#   匹配字符串 “There” ，将包含这个字符串的行打印并输出
awk '/There/{print $0}' poetry.txt

There is nothing either good or bad, but thinking makes it so
There’s a special providence in the fall of a sparrow

#   匹配一个包含字母 t 和字母 e 并且 t 和 e 中间只能有任意单个字符的行
awk '/t.e/{print $0}' poetry.txt

There is nothing either good or bad, but thinking makes it so
There’s a special providence in the fall of a sparrow
No matter how dark long, may eventually in the day arrival

#   以 “The” 字符串开头的行
awk '/^The/{print $0}' poetry.txt

#   以 “true” 字符串结尾的行
awk '/true$/{print $0}' poetry.txt

#   /s[a-z]/ 表示匹配包含字符 s 然后后面跟着任意 a 到 z 之间的单个字符的字符串
awk '/s[a-z]/{print $0}' poetry.txt

#     字母 "o" 只能可以出现 2 次，3 次，4 次，5 次，6 次 ... 一直到 10 次
awk '/go{2,10}d/{print $0}' poetry.txt

#   字母 "o" 必须至少出现 2 次或着 2 次以上
awk '/go{2,}d/{print $0}' poetry.txt

#   星号表示字符匹配 0 次或者多次
#   加号表示字符匹配 1 个或者 1 个以上
#   问号字符只能出现 0 次 或者 1 次
awk '/go*d/{print $0}' poetry.txt
awk '/go+d/{print $0}' poetry.txt
awk '/go?d/{print $0}' poetry.txt
```

##  使用 AWK 移除行中特定模式
文件中有行数据
```
/abc/def/123 456
/abc/def/222 456
```
想要移除 123，保留之前的字母和后面的数字，则可以使用
```shell
awk 'sub(/[0-9]+/,"",$1)' /path/to/file
```

##  print和printf
+   awk中同时提供了print和printf两种打印输出的函数。
+   print函数的参数可以是变量、数值或者字符串。字符串必须用双引号引用，参数用逗号分隔。如果没有逗号，参数就串联在一起而无法区分。这里，逗号的作用与输出文件的分隔符的作用是一样的，只是后者是空格而已
+   printf函数，其用法和c语言中printf基本相似,可以格式化字符串,输出复杂时，printf更加好用，代码更易懂

#   awk 编程

##  BEGIN 和 END 关键字的使用
+   BEGIN:会在开始读取一个文件之前，运行一次 BEGIN 关键字后面的脚本代码段
+   END:读取并且处理完文件的所有内容行之后，才会执行 END 后面的脚本代码段

```shell
cat /etc/passwd |awk  -F ':'  'BEGIN {print "name,shell"}  {print $1","$7} END {print "blue,/bin/nosh"}'
name,shell  # BEGIN多这一行
root,/bin/bash
daemon,/bin/sh
bin,/bin/sh
sys,/bin/sh
....
blue,/bin/nosh # END多这一行
```

##  在 awk 中使用变量
###     可以在 awk 脚本中声明和使用变量
```shell
awk '{msg="hello world"; print msg}' /etc/passwd
```
awk 声明的变量可以在任何多个花括号脚本中使用
```shell
awk 'BEGIN {msg="hello world"} {print msg}' /etc/passwd
```
在 awk 中使用数学运算，在 awk 中，像其他编程语言一样，它也支持一些基本的数学运算操作
```shell
awk '{a = 12; b = 24; print a + b}' company.txt
```
上面这段脚本表示，先声明两个变量 a = 12 和 b = 24，然后用 print 打印出 a 加上 b 的结果
awk 还支持其他的数学运算符
```
+ 加法运算符
- 减法运算符
* 乘法运算符
/ 除法运算符
% 取余运算符
```

###     awk 内置变量的使用
+   0这个表示文本处理时的当前行，1 表示文本行被分隔后的第 1 个字段列，2表示文本行被分割后的第2个字段列，3 表示文本行被分割后的第 3 个字段列，$n 表示文本行被分割后的第 n 个字段列
+   NR 表示文件中的行号，表示当前是第几行
```shell
awk '{print NR "\t" $0}' fruit.txt

1   peach    100   Mar  1997   China
2   Lemon    150   Jan  1986   America
3   Pear     240   Mar  1990   Janpan
4   avocado  120   Feb  2008   china
```
+   NF 表示文件中的当前行被分割的列数，可以理解为 MySQL 数据表里面每一条记录有多少个字段，所以 NF就表示最后一个字段，(NF-1) 就表示倒数第二个字段
```shell
awk '{print NF "\t" $0}' fruit.txt

5   peach    100   Mar  1997   China
5   Lemon    150   Jan  1986   America
5   Pear     240   Mar  1990   Janpan
5   avocado  120   Feb  2008   china

awk '{print $(NF - 1)}' fruit.txt

1997
1986
1990
2008

awk 'NR % 6'        # 打印出了 6 倍数行之外的其他行
awk 'NR > 5'        # 打印第 5 行之后内容，类似 `tail -n +6` 或者 `sed '1,5d'`
awk 'NF >= 6'       # 打印大于等于 6 列的行
awk '/foo/ && /bar/'    # 打印匹配 `/foo/` 和 `/bar/` 的行
awk '/foo/ && !/bar/'   # 打印包含 `/foo/` 不包含 `/bar/` 的行
awk '/foo/ || /bar/'    # 或
awk '/foo/,/bar/'       # 打印从匹配 `/foo/` 开始的行到 `/bar/` 的行，包含这两行
```
+   FS 表示 awk 的输入分隔符，默认分隔符为空格和制表符，可以对其进行自定义设置
+   OFS 表示 awk 的输出分隔符，默认为空格，也可以对其进行自定义设置
+   FILENAME 表示当前文件的文件名称，如果同时处理多个文件，它也表示当前文件名称
+   RS 行分隔符，用于分割行，默认为换行符
+   ORS 输出记录的分隔符，默认为换行符

##  条件语句

awk中的条件语句是从C语言中借鉴来的，见如下声明方式：
```shell
if (expression) {
    statement;
    statement;
    ... ...
}

if (expression) {
    statement;
} else {
    statement2;
}

if (expression) {
    statement1;
} else if (expression1) {
    statement2;
} else {
    statement3;
}
```
统计某个文件夹下的文件占用的字节数,过滤4096大小的文件(一般都是文件夹):
```
ls -l |awk 'BEGIN {size=0;print "[start]size is ", size} {if($5!=4096){size=size+$5;}} END{print "[end]size is ", size/1024/1024,"M"}' 
[end]size is  8.22339 M
```

##  循环语句
awk中的循环语句同样借鉴于C语言，支持while、do/while、for、break、continue，这些关键字的语义和C语言中的语义完全相同。

##  数组
因为awk中数组的下标可以是数字和字母，数组的下标通常被称为关键字(key)。值和关键字都存储在内部的一张针对key/value应用hash的表格里。由于hash不是顺序存储，因此在显示数组内容时会发现，它们并不是按照你预料的顺序显示出来的。数组和变量一样，都是在使用时自动创建的，awk也同样会自动判断其存储的是数字还是字符串。一般而言，awk中的数组用来从记录中收集信息，可以用于计算总和、统计单词以及跟踪模板被匹配的次数等等。

```shell
#   显示/etc/passwd的账户
#   这里使用for循环遍历数组
awk -F ':' 'BEGIN {count=0;} {name[count] = $1;count++;}; END{for (i = 0; i < NR; i++) print i, name[i]}' /etc/passwd
0 root
1 daemon
2 bin
3 sys
4 sync
5 games
......
```

##  内置函数
+   toupper() 用于将字符转为大写
+   tolower() 将字符转为小写
+   length() 长度
+   substr() 子字符串
+   sin() 正弦
+   cos() 余弦
+   sqrt() 平方根
+   rand() 随机数

更多的方法可以参考：man awk

#   参考
1.  [http://www.gnu.org/software/gawk/manual/gawk.html](http://www.gnu.org/software/gawk/manual/gawk.html)
2.  [linux awk命令详解](https://www.cnblogs.com/ggjucheng/archive/2013/01/13/2858470.html)
3.  [每天学习一个命令：awk 处理文本 ](http://einverne.github.io/post/2018/01/awk.html)
