---
title: 项目遇到的问题之Kafka
date: 2017-09-15 11:21:34
description: 项目遇到的问题之Kafka
categories:
- BigData
tags:
- Kafka
- 项目遇到的问题
---
#   Kafka挂掉
短期没事,因为

+   Flume记录
+   日志有记录

#   Kafka消息数据积压，Kafka消费能力不足怎么处理？ 
1.  如果是Kafka消费能力不足，则可以考虑增加Topic的分区数，并且同时提升消费组的消费者数量，消费者数=分区数。（两者缺一不可）

2.  如果是下游的数据处理不及时：提高每批次拉取的数量。批次拉取数据过少（拉取数据/处理时间<生产速度），使处理的数据小于生产的数据，也会造成数据积压。


#   Kafka数据重复
在下一级消费者中去重。（redis、SparkStreaming）

